{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login, notebook_login\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline, BitsAndBytesConfig, AutoConfig\n",
    "import torch\n",
    "from textwrap import fill\n",
    "from langchain.prompts import PromptTemplate\n",
    "import locale\n",
    "\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /home/liam/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login, notebook_login\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b40b61f4b240b2880dafbf01f716da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\" \n",
    "\n",
    "quantization_config = BitsAndBytesConfig()\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             device_map=\"cuda\",\n",
    "                                             quantization_config=quantization_config,\n",
    "                                             trust_remote_code=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "gen_cfg = GenerationConfig.from_pretrained(model_name)\n",
    "gen_cfg.max_new_tokens=512\n",
    "gen_cfg.temperature=0.0000001 \n",
    "gen_cfg.return_full_text=True\n",
    "gen_cfg.do_sample=True\n",
    "gen_cfg.repetition_penalty=1.11\n",
    "\n",
    "pipe=pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    generation_config=gen_cfg\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_llama3 = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Use the following context to answer the question at the end. Report anything that remotely resembles what the question is asking. \n",
    "Be sure to be specific in describing what you are reporting. If you do not have enough information to answer the \n",
    "question, state that, then report similar figures. Cite the statements you use in your response by company and form type.\n",
    "\n",
    "{context}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "prompt_template=prompt_template_llama3\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liam/VSCodeProjects/EDGAR-RAG/env/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embedding_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {\"device\": \"cuda\"}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_name,\n",
    "    model_kwargs=model_kwargs\n",
    ")\n",
    "\n",
    "vector_store = FAISS.load_local(\"vector_db\", embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "Chain_pdf = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={'k': 5, 'score_threshold': 0.2}),\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant queries\n",
    "query = \"How much did Apple Inc. spend of research and development in the last year?\"\n",
    "result = Chain_pdf.invoke(query)\n",
    "print(result['result'].strip())\n",
    "\n",
    "query = \"What was the most recent return on equity (ROE) for JPMorgan Chase & Co.?\"\n",
    "result = Chain_pdf.invoke(query)\n",
    "print(result['result'].strip())\n",
    "\n",
    "query = \"What was the inventory turnover ratio for Costco Wholesale Corporation in the last quarter?\"\n",
    "result = Chain_pdf.invoke(query)\n",
    "print(result['result'].strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
