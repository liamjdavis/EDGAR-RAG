{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login, notebook_login\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline, BitsAndBytesConfig, AutoConfig\n",
    "import torch\n",
    "from textwrap import fill\n",
    "from langchain.prompts import PromptTemplate\n",
    "import locale\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.vectorstores.utils import filter_complex_metadata\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /home/ubuntu/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login, notebook_login\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading documents\n"
     ]
    },
 
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1094664\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "import os\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# get all .md files in the statements/ directory and its subdirectories\n",
    "md_files = []\n",
    "for root, dirs, files in os.walk('statements'):\n",
    "    for file in files:\n",
    "        if file.endswith('.md'):\n",
    "            md_files.append(os.path.join(root, file))\n",
    "\n",
    "# create loaders for each .md file\n",
    "loaders = [UnstructuredMarkdownLoader(fn) for fn in md_files]\n",
    "\n",
    "def process_loader(loader):\n",
    "    md_doc = loader.load()\n",
    "    updated_md_doc = filter_complex_metadata(md_doc)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=256)\n",
    "    documents = text_splitter.split_documents(updated_md_doc)\n",
    "    return documents\n",
    "\n",
    "chunked_md_doc = []\n",
    "\n",
    "print(\"loading documents\")\n",
    "with ProcessPoolExecutor(max_workers=30) as executor:\n",
    "    futures = [executor.submit(process_loader, loader) for loader in loaders]\n",
    "    for future in as_completed(futures):\n",
    "        logging.info(f\"Process {future} completed\")\n",
    "        chunked_md_doc.extend(future.result())\n",
    "\n",
    "print(len(chunked_md_doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4337ee5abd874eaba2792f67c346f2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\" \n",
    "\n",
    "quantization_config = BitsAndBytesConfig()\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             device_map=\"cuda\",\n",
    "                                             quantization_config=quantization_config,\n",
    "                                             trust_remote_code=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "gen_cfg = GenerationConfig.from_pretrained(model_name)\n",
    "gen_cfg.max_new_tokens=512\n",
    "gen_cfg.temperature=0.0000001 \n",
    "gen_cfg.return_full_text=True\n",
    "gen_cfg.do_sample=True\n",
    "gen_cfg.repetition_penalty=1.11\n",
    "\n",
    "pipe=pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    generation_config=gen_cfg\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_llama3 = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Use the following context to answer the question at the end. Report anything that remotely resembles what the question is asking. Be sure to be specific in describing\n",
    "what you are reporting. If you do not have enough information to answer the question, state that, then report similar figures.\n",
    "\n",
    "{context}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "prompt_template=prompt_template_llama3\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/env/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "2024-08-13 17:50:10,398 - INFO - PyTorch version 2.4.0 available.\n",
      "2024-08-13 17:50:10,602 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1949da5b58614552b366258fa212f2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b133fca60aa430d9748ad5596b5430c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db45a91616346358fa60822319efa73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1e4bda290047debf8d09a1310b1373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74bc88e703a2497f802ce8bed04bba14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e866efa3ec3847f987b39cce5fc63d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a10f8b9824748dfa24686c43d4114be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524f2e1654824ddbafa51e6b9dc45f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5dadda3b8eb4b16931a401aa2b0c4fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8840b5b14c154602a9fb76138d8b252d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3231e25b0d1249d4bef86341498102cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 17:50:14,215 - INFO - Start multi-process pool on devices: cuda:0\n",
      "2024-08-13 19:11:42,501 - INFO - Loading faiss with AVX2 support.\n",
      "2024-08-13 19:11:42,502 - INFO - Could not load library with AVX2 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
      "2024-08-13 19:11:42,503 - INFO - Loading faiss.\n",
      "2024-08-13 19:11:42,556 - INFO - Successfully loaded faiss.\n"
     ]
    }
   ],
   "source": [
    "embedding_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {\"device\": \"cuda\"}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    multi_process=True,\n",
    ")\n",
    "\n",
    "vector_store = FAISS.from_documents(chunked_md_doc, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 19:54:24,981 - INFO - Start multi-process pool on devices: cuda:0\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2024-08-13 19:54:54,040 - INFO - Start multi-process pool on devices: cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>  Use the following context to answer the question at the end. Report anything that remotely resembles what the question is asking. Be sure\n",
      "to be specific in describing what you are reporting. If you do not have enough information to answer the question, state that, then report similar figures.  1 Three Months Ended June 30, Six Months\n",
      "Ended June 30, 2 2024 2023 2024 2023 3 United States $ 1,147,168 $ 965,997 $ 2,248,172 $ 2,004,892 4 United Kingdom 42,698 53,563 80,223 86,760 5 Canada 10,610 6,853 22,230 28,831 6 Other 17,456\n",
      "24,308 30,345 37,031 7 $ 1,217,932 $ 1,050,721 $ 2,380,970 $ 2,157,514  45  NOTE 23 – Earnings Per Share (“EPS”)  EARNINGS PER SHARE (EPS)  Earnings Per Share (EPS)  Earnings per Share (EPS)  (11)\n",
      "Earnings per Share (EPS)  5,407 0.59 25 Quantic Electronics, LLC ^* (2)(3)(11)(15) Aerospace & Defense SOFR 6.25% 11.68% 11/19/2020 11/19/2026 14,946 14,793 14,776 1.62 26 Quantic Electronics, LLC ^*\n",
      "(2)(3)(11) Aerospace & Defense SOFR 6.25% 11.68% 3/1/2021 3/1/2027 9,676 9,575 9,570 1.05 27 Radwell Parent, LLC ^* (2)(3)(15) Wholesale SOFR 5.50% 10.83% 12/1/2022 4/1/2029 11,160 10,867 11,201 1.23\n",
      "28 Regency Entertainment, Inc. ^ (2)(3)(11) Media: Advertising, Printing & Publishing SOFR 8.50% 13.93% 7/5/2023 6/23/2028 15,000 14,682 14,918 1.64 29 RSC Acquisition, Inc. ^ (2)(3)(11)(15)\n",
      "Diversified Financial Services SOFR 5.50% 10.98% 11/1/2019 11/1/2029 10,116 10,045 9,903 1.09 30 SCP Eye Care HoldCo, LLC ^ (2)(3)(15) Healthcare & Pharmaceuticals SOFR 5.50% 10.94% 10/7/2022\n",
      "10/7/2029 144 140 142 0.02 31 Smarsh Inc. ^ (2)(3)(15) Software SOFR 5.75% 11.08% 2/18/2022 2/18/2029 7,542 7,417 7,542 0.83 32 SPay, Inc. ^* (2)(3)(11) Leisure Products & Services SOFR 2.88%,6.38%\n",
      "PIK 14.73% 6/15/2018 6/15/2026 27,924 27,869 24,230 2.66  Earnings Per Common Share (EPS). The computation of weighted average shares outstanding and the basic and diluted earnings per common share\n",
      "for the three and six-month periods ended June 30, 2024 and 2023 consisted of the following (in thousands, except per share amounts): ​ | | | | | | | | | | | | | | | |\n",
      "|---:|:-----------------------------------------------------------|:---|:-------------------|:-------|:-----------------|:---|:-------|:---|:-----|:-------|:---|:---|:-------|:---| | 0 | ​ | ​ | ​ | ​\n",
      "| ​ | ​ | ​ | ​ | ​ | ​ | ​ | ​ | ​ | ​ | | 1 | ​ | ​ | Three Months Ended | ​ | Six Months Ended | ​ | | | | | | | | | | 2 | ​ | ​ | June 30, | ​ | June 30, | ​ | | | | | | | | | | 3 | ​ | ​ | 2024 |\n",
      "​ | 2023 | ​ | 2024 | ​ | 2023 | ​ | | | | | | 4 | Net income | ​ | $ | 35,726 | ​ | $ | 20,245 | ​ | $ | 63,966 | ​ | $ | 40,948 | ​ | | 5 | Average common shares outstanding | ​ | | 58,139 | ​ | |\n",
      "57,537 | ​ | | 58,049 | ​ | | 57,445 | ​ | | 6 | Basic EPS | ​ | $ | 0.61 | ​ | $ | 0.35 | ​ | $ | 1.10 | ​ | $ |  Earnings per Share (“EPS”)  NOTE 12. EARNINGS PER SHARE (EPS)  Aerospace & Defense\n",
      "SOFR 7.00% 12.38% 11/2/2022 11/2/2029 5,302 5,127 5,420 0.59 13 Quantic Electronics, LLC ^* (2)(3)(11) Aerospace & Defense SOFR 6.25% 11.70% 11/19/2020 11/19/2026 15,711 15,528 15,270 1.67 14 Quantic\n",
      "Electronics, LLC ^* (2)(3)(11) Aerospace & Defense SOFR 6.25% 11.70% 3/1/2021 3/1/2027 9,725 9,609 9,452 1.04 15 Radwell Parent, LLC ^* (2)(3)(15) Wholesale SOFR 6.75% 12.10% 12/1/2022 4/1/2029 11,169\n",
      "10,849 11,242 1.23 16 Regency Entertainment, Inc. ^ (2)(3)(11) Media: Advertising, Printing & Publishing SOFR 8.50% 13.95% 7/5/2023 6/23/2028 15,000 14,653 14,891 1.63 17 RSC Acquisition, Inc. ^\n",
      "(2)(3)(11)(15) Diversified Financial Services SOFR 5.50% 10.93% 11/1/2019 11/1/2029 10,168 10,088 10,099 1.11 18 Sapphire Convention, Inc. ^* (2)(3)(11)(15) Telecommunications SOFR 6.00% 11.53%\n",
      "11/20/2018 11/20/2025 27,479 27,302 27,479 3.01 19 SCP Eye Care HoldCo, LLC ^ (2)(3)(11)(15) Healthcare & Pharmaceuticals SOFR 5.75% 11.21% 10/7/2022 10/7/2029 158 152 156 0.02 20 Smarsh Inc. ^\n",
      "(2)(3)(15) Software<|eot_id|><|start_header_id|>user<|end_header_id|>  What are the top 10 companies in terms of EPS?<|eot_id|><|start_header_id|>assistant<|end_header_id|> Based on the provided data,\n",
      "I can extract the top 10 companies by their respective EPS values for both the three months and six months ended June 30, 2024 and 2023. However, please note that the data only provides a snapshot of\n",
      "the companies' performance during these two time periods and may not reflect their overall performance or ranking over a longer period.  Here are the top 10 companies by EPS for each period:  **Three\n",
      "Months Ended June 30, 2024**  1. **Smarsh Inc.**: $0.83 2. **SCP Eye Care HoldCo, LLC**: $0.02 3. **Regency Entertainment, Inc.**: $1.64 4. **RSC Acquisition, Inc.**: $1.11 5. **Radwell Parent, LLC**:\n",
      "$1.23 6. **Quantic Electronics, LLC**: $1.67 7. **Quantic Electronics, LLC**: $1.04 8. **Sapphire Convention, Inc.**: $3.01 9. **Regency Entertainment, Inc.**: $1.63 10. **Radwell Parent, LLC**: $1.23\n",
      "**Six Months Ended June 30, 2024**  1. **Smarsh Inc.**: $0.83 2. **SCP Eye Care HoldCo, LLC**: $0.02 3. **Regency Entertainment, Inc.**: $1.64 4. **RSC Acquisition, Inc.**: $1.11 5. **Radwell Parent,\n",
      "LLC**: $1.23 6. **Quantic Electronics, LLC**: $1.67 7. **Quantic Electronics, LLC**: $1.04 8. **Sapphire Convention, Inc.**: $3.01 9. **Regency Entertainment, Inc.**: $1.63 10. **Radwell Parent,\n",
      "LLC**: $1.23  Please note that there might be some discrepancies due to rounding differences between the two periods.\n",
      "##########################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2024-08-13 19:55:04,709 - INFO - Start multi-process pool on devices: cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>  Use the following context to answer the question at the end. Report anything that remotely resembles what the question is asking. Be sure\n",
      "to be specific in describing what you are reporting. If you do not have enough information to answer the question, state that, then report similar figures.  451,707 406,428 14 Goodwill and other\n",
      "intangible assets (net of accumulated amortization of $67,711 and $67,681 at June 30, 2024 and December 31, 2023, respectively) 373,147 373,604 15 Deferred tax assets 64,928 52,225 16 Other assets\n",
      "445,647 398,983 17 Total Assets $ 4,131,363 $ 4,230,325  2 (in millions, except share amounts) As of June 30, 2024 (unaudited) As of December 31, 2023 3 Assets 4 Current assets: 5 Cash and cash\n",
      "equivalents $ 391.2 $ 337.9 6 Investments 48.0 51.1 7 Accounts receivable, less allowance for credit losses of $7.5 million and $5.6 million, respectively 336.4 343.9 9 Income tax receivable, net —\n",
      "0.6 10 Deferred commissions 40.5 41.9 11 Prepaid expenses 45.3 34.9 12 Other current assets 14.4 5.4 13 Total current assets 875.8 815.7 14 Goodwill 1,569.5 1,578.8 15 Intangible assets, net 443.1\n",
      "484.4 16 Property, equipment, and capitalized software, less accumulated depreciation and amortization of $758.7 million and $714.0 million, respectively 210.3 207.7 17 Operating lease assets 148.1\n",
      "163.9 18 Investments in unconsolidated entities 97.3 100.2 19 Deferred tax assets, net 24.2 14.6 20 Deferred commissions 27.8 29.3 21 Other assets 7.4 8.8 22 Total assets $ 3,403.5 $ 3,403.4 24\n",
      "Liabilities and equity 25 Current liabilities: 26 Deferred revenue $ 548.2 $ 517.7 27 Accrued  16  Intangible assets, net, consisted of the following at December 31, 2023:  1 December 31, 2023 2\n",
      "GrossCarryingValue AccumulatedAmortization NetCarryingValue WeightedAverageUseful Life(in years) 3 (Amounts in thousands) 4 Finite-lived intangible assets: 5 Technology - developed $ 249,594 $ (44,162\n",
      ") $ 205,432 16 6 Patents 240 (240 ) — 8 7 Customer relationships 269,949 (83,963 ) 185,986 15 8 Trademarks 8,757 (1,789 ) 6,968 19 9 Other intangibles 3,914 (2,514 ) 1,400 3 10 Total finite-lived\n",
      "intangible assets 532,454 (132,668 ) 399,786 15 11 Indefinite-lived intangible asset: 12 Trademarks 700 — 700 — 13 Total intangible assets $ 533,154 $ (132,668 ) $ 400,486  | (64,462) | | | (61,732) |\n",
      "| | | 24 | Total net assets | $ | 287,812 | | | $ | 290,542 | | 25 | Total liabilities and net assets | $ | 435,889 | | | $ | 465,028 | | 27 | Shares of common stock outstanding (par value $0.01 per\n",
      "share and 450,000,000 shares authorized) | 23,689,363 | | | 23,689,363 | | | | 28 | Net asset value per common share | $ | 12.13 | | | $ | 12.24 | See accompanying notes to consolidated financial\n",
      "statements.  | | | | | | | | 4 | Technology | $ | 1,590 | | | $ | (919) | | $ | 671 | | $ | 1,575 | | $ | (806) | $ | 769 | | 5 | Customer relationships | 2,790 | | | (1,562) | | | 1,228 | | 3,047 | |\n",
      "(1,496) | | 1,551 | | | | | | 6 | Miscellaneous | 968 | | | (509) | | | 459 | | 889 | | (435) | | 454 | | | | | | 7 | | 5,348 | | | (2,990) | | | 2,358 | | 5,511 | | (2,737) | | 2,774 | | | | | | 8 |\n",
      "Indefinite-lived intangible assets | | | | | | | | | | | | | | | | | | | 9 | Trademarks/trade names | 1,957 | | | — | | | 1,957 | | 2,114 | | — | | 2,114 | | | | | | 12 | Total intangible assets | $ |\n",
      "7,305 | | | $ | (2,990) | | $ | 4,315 | | $ | 7,625 | | $ | (2,737) | $ | 4,888 | Amortization of other intangible assets for the three months ended June 30, 2024 and 2023 was $119 million and $111\n",
      "million, respectively. Amortization of other intangible assets for the nine months ended June 30, 2024 and 2023 was $366 million and $319 million, respectively.  Trade Names 1,300,000 — 1,300,000\n",
      "Indefinite 15 Guardian In-Process R&D 6,800,000 — 6,800,000 Indefinite 16 Total Other Intangible Assets $ 410,755,910 $ (196,750,000) $ 214,005,910 18 Total Patents & Other Intangible Assets $\n",
      "449,955,017 $ (224,519,803) $ 225,435,214  (in thousands, except share and per share data) (unaudited)  NOTE 3. INTANGIBLE ASSETSIntangiblesIntangible assets as of June 30, 2024, were as follows: | |\n",
      "| | | | | | | | | | |---:|:---------------------------------------------------|:---|:----------------------|:-------|:-------------------------|:---|:--------------------|:---|:---|:-------| | 0 | ​ |\n",
      "​ | ​ | ​ | ​ | ​ | ​ | ​ | ​ | ​ | | 1 | ​ | | Gross Carrying Amount | | Accumulated Amortization | | Net Carrying Amount | | | | | 2 | Trademarks and tradenames, indefinite-lived | ​ | $ | 607 | ​ |\n",
      "$ | — | ​ | $ | 607 | | 3 | Patents, trademarks and tradenames, definite-lived | ​ | ​ | 8,718 | ​ | ​ | 2,995 | ​ | ​ | 5,723 | | 4 | Customer relationships | ​ | ​ | 1,733 | ​ | ​ | 705 | ​ | ​ |\n",
      "1,028 | | 5 | Developed technology | ​ | ​ | 17,690 | ​ | ​ | 4,071 | ​ | ​ | 13,619 | | 6 | Other intangibles | ​ | ​ | 30 | ​ | ​ | 30 | ​ | ​ | — | | 7 | Total intangible assets, net | ​ | $ |\n",
      "28,778 | ​ | $ | 7,801 | ​ | $ | 20,977 |  1 June 30, 2024 December 31, 2023 2 (in thousands) 3 United States $ 44,248 $ 32,161 4 International 18,691 15,210 5 Total $ 62,939 $ 47,371  Note\n",
      "7—Intangible Assets  The Company’s intangible assets as of June 30, 2024 and December 31, 2023 included the following:  1 June 30, 2024 December 31, 2023 2 (in thousands) 3 Amortizable intangible\n",
      "assets: 4 Developed technology $ 109,736 $ 109,736 5 Customer relationships 37,300 37,300 6 In-process research and development 8,830 8,830 8 Trademarks 900 900 9 Non-compete agreements — 200 10 Total\n",
      "identifiable intangible assets, gross 156,766 156,966 11 Accumulated amortization—intangible assets: 12 Developed technology (84,631) (75,321) 13 Customer relationships (29,529) (24,867) 14 In-process\n",
      "research and development (5,858) (4,832) 16 Trademarks (900) (750) 17 Non-compete agreements — (185) 18 Total accumulated amortization—intangible assets (120,918) (105,955) 19 Total identifiable\n",
      "intangible assets, net $ 35,848 $ 51,011  Intangible Assets. Intangible assets consisted of the following:  1 Gross Carrying Amount (a) Accumulated Amortization Net Carrying Amount Gross Carrying\n",
      "Amount (a) Accumulated Amortization Net Carrying Amount 2 June 30, 2024 December 31, 2023 3 Contract and program intangible assets (b) $ 3,245 $ (1,939) $ 1,306 $ 3,256 $ (1,868) $ 1,388 4 Trade names\n",
      "and trademarks 511 (280) 231 542 (288) 254 5 Technology and software 65 (52) 13 65 (51) 14 6 Other intangible assets 63 (63) — 64 (64) — 7 Total intangible assets $ 3,884 $ (2,334) $ 1,550 $ 3,927 $\n",
      "(2,271) $ 1,656  23 Patents, trademarks and other intangible assets, net of accumulated amortization of $53,480 in 2024 and $51,509 in 2023 27,026 29,132 26 Operating lease right-of-use assets 30,217\n",
      "31,915 27 Investments 20,427 17,354 28 Other assets 10,850 10,829 29 Total other assets 88,520 89,230 30 Total assets $ 499,725 $ 478,961<|eot_id|><|start_header_id|>user<|end_header_id|>  What were\n",
      "the total assets of Google (Alphabet Inc.)?<|eot_id|><|start_header_id|>assistant<|end_header_id|> According to the provided text, the total assets of Alphabet Inc. (Google) were:  * As of June 30,\n",
      "2024: $4,131,363 million * As of December 31, 2023: $4,230,325 million\n",
      "##########################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>  Use the following context to answer the question at the end. Report anything that remotely resembles what the question is asking. Be sure\n",
      "to be specific in describing what you are reporting. If you do not have enough information to answer the question, state that, then report similar figures.  Brazil  June 30, 2024 |  June 30, 2024 |\n",
      "June 30, 2024 |<|eot_id|><|start_header_id|>user<|end_header_id|>  Who was the winner of the 2022 World Cup?<|eot_id|><|start_header_id|>assistant<|end_header_id|> I'm unable to verify who won the\n",
      "2022 FIFA World Cup. However, I can tell you that Argentina won the tournament by defeating France 4-2 in a penalty shootout after the game ended 3-3 after extra time.\n"
     ]
    }
   ],
   "source": [
    "Chain_pdf = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={'k': 10, 'score_threshold': 0.2}),\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    ")\n",
    "query = \"What are the top 10 companies in terms of EPS?\"\n",
    "result = Chain_pdf.invoke(query)\n",
    "print(fill(result['result'].strip(), width=200))\n",
    "print(\"##########################################################################\")\n",
    "query = \"What were the total assets of Google (Alphabet Inc.)?\"\n",
    "result = Chain_pdf.invoke(query)\n",
    "print(fill(result['result'].strip(), width=200))\n",
    "print(\"##########################################################################\")\n",
    "query = \"Who was the winner of the 2022 World Cup?\"\n",
    "result = Chain_pdf.invoke(query)\n",
    "print(fill(result['result'].strip(), width=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7f3ad1fd9047fc984f03416b7b826e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "faiss_index.bin:   0%|          | 0.00/3.36G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index saved and uploaded to Hugging Face Hub at liamjdavis/llama3.1-edgar-rag/faiss_index.bin\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, HfFolder, Repository\n",
    "import faiss\n",
    "\n",
    "# Save the FAISS index to a file\n",
    "index_file = \"faiss_index.bin\"\n",
    "faiss.write_index(vector_store.index, index_file)\n",
    "\n",
    "# Initialize Hugging Face API\n",
    "api = HfApi()\n",
    "repo_id = \"liamjdavis/llama3.1-edgar-rag\"\n",
    "\n",
    "# Create a repository if it doesn't exist\n",
    "api.create_repo(repo_id, exist_ok=True)\n",
    "\n",
    "# Upload the FAISS index file to the repository\n",
    "api.upload_file(\n",
    "    path_or_fileobj=index_file,\n",
    "    path_in_repo=index_file,\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"model\"\n",
    ")\n",
    "\n",
    "print(f\"FAISS index saved and uploaded to Hugging Face Hub at {repo_id}/{index_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
